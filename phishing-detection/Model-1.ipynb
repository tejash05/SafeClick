{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d4154b-1066-419b-8f5d-5578baa867a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # For saving the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd78d7da-68f5-47a1-9183-5be1cbe28fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ **Step 1: Load the Dataset**\n",
    "file_path = \"urldata.csv\"  # Change this to your dataset path\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec547b1-507d-47d4-b089-2ef16cf10a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0251a55a-ab67-4f51-9d13-0ca3e1d3459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical format\n",
    "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc7410b-2faf-4adf-a6b5-29132abe88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size to 100,000 samples for memory efficiency\n",
    "df_sampled = df.groupby(\"label\").sample(n=50000, random_state=42)  # Balance both classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e7ba40-c070-4a1f-890c-17d86f864514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ **Step 2: Feature Extraction**\n",
    "def extract_url_features(url):\n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b49834-cf25-4c37-a6c8-29cf08785545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature extraction\n",
    "df_features = df_sampled[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())  # Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07b9c19-fb09-4f82-aad6-52bd683128f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "y_sampled = df_sampled[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf8f907-d4e4-44db-b38d-649605305c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ **Step 3: Train-Test Split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328c9bdc-2eb0-42f5-9129-df11c00c2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ **Step 4: Train XGBoost Model**\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919ac7cc-5239-4b01-8f0d-c73521e7e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:17:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6552b451-2b46-4be7-bd64-a34672b6385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ **Step 5: Evaluate the Model**\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ea7e67-c83e-4ada-a166-360788b38a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Model Accuracy: 0.8465\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85     10000\n",
      "           1       0.86      0.82      0.84     10000\n",
      "\n",
      "    accuracy                           0.85     20000\n",
      "   macro avg       0.85      0.85      0.85     20000\n",
      "weighted avg       0.85      0.85      0.85     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ”¹ Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"ðŸ”¹ Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "187e1a07-21c8-4d72-ab26-4757827c8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ URL: http://free-bitcoin-claim.com â†’ Prediction: Malicious\n"
     ]
    }
   ],
   "source": [
    "def extract_url_features(url):\n",
    "    import re\n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\")\n",
    "    }\n",
    "\n",
    "# ðŸš€ **Step 2: Prepare the URL for Prediction**\n",
    "url_to_test = \"http://free-bitcoin-claim.com\"  # Replace with any URL you want to test\n",
    "\n",
    "# Convert URL to feature format\n",
    "url_features = pd.DataFrame([extract_url_features(url_to_test)])\n",
    "\n",
    "# ðŸš€ **Step 3: Make Prediction Using Your Trained Model**\n",
    "prediction = xgb_model.predict(url_features)\n",
    "\n",
    "# ðŸš€ **Step 4: Display the Result**\n",
    "result = \"Malicious\" if prediction[0] == 1 else \"Benign (Safe)\"\n",
    "print(f\"ðŸ”¹ URL: {url_to_test} â†’ Prediction: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca6e936-06f5-4707-a15e-86f5c4112d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ðŸš€ **Step 1: Prepare Data (Use Your Existing Feature Extraction)**\n",
    "df_sampled = df.groupby(\"label\").sample(n=50000, random_state=42)  # Balanced dataset\n",
    "\n",
    "# Convert URLs to extracted features\n",
    "df_features = df_sampled[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())\n",
    "\n",
    "# Labels\n",
    "y_sampled = df_sampled[\"label\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c957912d-df3e-4741-8020-8077669ed22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False)\n",
    "\n",
    "# ðŸš€ **Step 3: Define Hyperparameter Grid for Tuning**\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400],  # Number of trees\n",
    "    \"max_depth\": [3, 6, 9],  # Depth of trees\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2, 0.3],  # Step size shrinkage\n",
    "    \"subsample\": [0.7, 0.8, 0.9],  # Fraction of samples used per tree\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],  # Fraction of features used per tree\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required for a split\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42e08a7f-339b-4141-9508-85915e486784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;logloss&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning...\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 6, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400],\n",
       "                                        &#x27;subsample&#x27;: [0.7, 0.8, 0.9]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;logloss&#x27;,\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning...\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.1, 0.2, 0.3],\n",
       "                                        &#x27;max_depth&#x27;: [3, 6, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400],\n",
       "                                        &#x27;subsample&#x27;: [0.7, 0.8, 0.9]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric='logloss',\n",
       "                                           feature_types=None, gamma=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning...\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, ...),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                                        'gamma': [0, 0.1, 0.2, 0.3],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [3, 6, 9],\n",
       "                                        'n_estimators': [100, 200, 300, 400],\n",
       "                                        'subsample': [0.7, 0.8, 0.9]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸš€ **Step 4: Perform Randomized Search for Best Hyperparameters**\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Number of different combinations to try\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99afaf86-4ecc-4b7d-946a-fa95eb089355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Parameters: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:51:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Improved Model Accuracy: 0.8532\n",
      "ðŸ”¹ Improved Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86     10000\n",
      "           1       0.87      0.83      0.85     10000\n",
      "\n",
      "    accuracy                           0.85     20000\n",
      "   macro avg       0.85      0.85      0.85     20000\n",
      "weighted avg       0.85      0.85      0.85     20000\n",
      "\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=9, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=400, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=9, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=300, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.3, learning_rate=0.2, max_depth=9, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=6, n_estimators=400, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=400, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=400, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.3, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=400, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.0s\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ **Step 5: Train Model with Best Parameters**\n",
    "best_params = random_search.best_params_\n",
    "print(f\"âœ… Best Parameters: {best_params}\")\n",
    "\n",
    "optimized_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    **best_params  # Use best found hyperparameters\n",
    ")\n",
    "\n",
    "optimized_model.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 6: Evaluate New Model**\n",
    "y_pred = optimized_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ”¹ Improved Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"ðŸ”¹ Improved Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e3bcbaf-b3c0-4c06-91bc-0e142fce324e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Parameters from Randomized Search: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [01:59:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Final Model Accuracy: 0.8619\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86     10000\n",
      "           1       0.88      0.84      0.86     10000\n",
      "\n",
      "    accuracy                           0.86     20000\n",
      "   macro avg       0.86      0.86      0.86     20000\n",
      "weighted avg       0.86      0.86      0.86     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ðŸš€ **Step 1: Load Dataset**\n",
    "file_path = \"urldata.csv\"  # Change this to your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns if present\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1})\n",
    "\n",
    "# Reduce dataset size to 100,000 samples for memory efficiency\n",
    "df_sampled = df.groupby(\"label\").sample(n=50000, random_state=42)  # Balance both classes\n",
    "\n",
    "# ðŸš€ **Step 2: Feature Extraction (Advanced URL Features)**\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "    \n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),  # New feature\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),  # New feature\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)  # New feature\n",
    "    }\n",
    "\n",
    "# Apply feature extraction\n",
    "df_features = df_sampled[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())\n",
    "\n",
    "# Labels\n",
    "y_sampled = df_sampled[\"label\"]\n",
    "\n",
    "# ðŸš€ **Step 3: Split Data into Train and Test Sets**\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)\n",
    "\n",
    "# ðŸš€ **Step 4: Define Hyperparameter Search Space**\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"max_depth\": [3, 6, 9, 12],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n",
    "\n",
    "# ðŸš€ **Step 5: Perform Randomized Search with K-Fold Cross-Validation**\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False)\n",
    "\n",
    "# Define K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Number of random combinations to test\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,  # Using K-Fold CV\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters from Randomized Search\n",
    "best_params_random = random_search.best_params_\n",
    "print(f\"âœ… Best Parameters from Randomized Search: {best_params_random}\")\n",
    "\n",
    "# ðŸš€ **Step 6: Train Final XGBoost Model with Best Parameters**\n",
    "optimized_xgb = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    **best_params_random  # Apply best parameters\n",
    ")\n",
    "\n",
    "optimized_xgb.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 7: Make Predictions**\n",
    "y_pred = optimized_xgb.predict(X_test)\n",
    "\n",
    "# ðŸš€ **Step 8: Evaluate Model Performance**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ”¹ Final Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"ðŸ”¹ Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56e40e75-2ff7-4b9d-a897-34e318a3c89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54ab8dcb-e72a-4d09-8071-997f5b74fe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:01:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Parameters from Grid Search: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.08000000000000002, 'max_depth': 10, 'n_estimators': 250, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:02:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Final Fine-Tuned Accuracy: 0.8622\n",
      "ðŸ”¹ Final Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87     10000\n",
      "           1       0.88      0.84      0.86     10000\n",
      "\n",
      "    accuracy                           0.86     20000\n",
      "   macro avg       0.86      0.86      0.86     20000\n",
      "weighted avg       0.86      0.86      0.86     20000\n",
      "\n",
      "âœ… Final Model saved as 'final_optimized_xgboost_model.pkl'\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=12, n_estimators=400, subsample=0.6; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=350, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=12, n_estimators=400, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=12, n_estimators=200, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=350, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=350, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=400, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.3, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=12, n_estimators=200, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=400, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=12, n_estimators=400, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=12, n_estimators=200, subsample=0.6; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=350, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=350, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=3, n_estimators=400, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=12, n_estimators=400, subsample=0.6; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=300, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=250, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=400, subsample=0.6; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.3, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.3, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=12, n_estimators=200, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=400, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=12, n_estimators=400, subsample=0.6; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=12, n_estimators=200, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=350, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=350, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=300, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.2, max_depth=6, n_estimators=400, subsample=0.6; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.2, max_depth=6, n_estimators=200, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.3, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.3, max_depth=9, n_estimators=200, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.7; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.3, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=9, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.08000000000000002, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=300, subsample=0.8; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=250, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=250, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=10, n_estimators=350, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=250, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=8, n_estimators=350, subsample=0.8; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=9, n_estimators=350, subsample=0.8; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=300, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.12, max_depth=10, n_estimators=350, subsample=0.8; total time=   1.9s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# ðŸš€ **Step 1: Load Dataset**\n",
    "file_path = \"urldata.csv\"  # Change this to your dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1})\n",
    "\n",
    "# Reduce dataset size to 100,000 samples for memory efficiency\n",
    "df_sampled = df.groupby(\"label\").sample(n=50000, random_state=42)  # Balance both classes\n",
    "\n",
    "# ðŸš€ **Step 2: Feature Extraction (Advanced URL Features)**\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "    \n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),  # New feature\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),  # New feature\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)  # New feature\n",
    "    }\n",
    "\n",
    "# Apply feature extraction\n",
    "df_features = df_sampled[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())\n",
    "\n",
    "# Labels\n",
    "y_sampled = df_sampled[\"label\"]\n",
    "\n",
    "# ðŸš€ **Step 3: Split Data into Train and Test Sets**\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)\n",
    "\n",
    "# ðŸš€ **Step 4: Use the Best Parameters from Randomized Search**\n",
    "best_params_random = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 9,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"gamma\": 0.1\n",
    "}\n",
    "\n",
    "# ðŸš€ **Step 5: Perform Grid Search for Fine-Tuning**\n",
    "param_grid = {\n",
    "    \"n_estimators\": [best_params_random[\"n_estimators\"] - 50, best_params_random[\"n_estimators\"], best_params_random[\"n_estimators\"] + 50],\n",
    "    \"max_depth\": [best_params_random[\"max_depth\"] - 1, best_params_random[\"max_depth\"], best_params_random[\"max_depth\"] + 1],\n",
    "    \"learning_rate\": [best_params_random[\"learning_rate\"] * 0.8, best_params_random[\"learning_rate\"], best_params_random[\"learning_rate\"] * 1.2],\n",
    "    \"subsample\": [best_params_random[\"subsample\"]],\n",
    "    \"colsample_bytree\": [best_params_random[\"colsample_bytree\"]],\n",
    "    \"gamma\": [best_params_random[\"gamma\"]]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False)\n",
    "\n",
    "# Define K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,  # 5-Fold Cross Validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 6: Train Final Model with Best Parameters**\n",
    "best_params_grid = grid_search.best_params_\n",
    "print(f\"âœ… Best Parameters from Grid Search: {best_params_grid}\")\n",
    "\n",
    "final_xgb = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    **best_params_grid\n",
    ")\n",
    "\n",
    "final_xgb.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 7: Make Predictions**\n",
    "y_pred_final = final_xgb.predict(X_test)\n",
    "\n",
    "# ðŸš€ **Step 8: Evaluate Model Performance**\n",
    "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "report_final = classification_report(y_test, y_pred_final)\n",
    "\n",
    "print(f\"ðŸ”¹ Final Fine-Tuned Accuracy: {accuracy_final:.4f}\")\n",
    "print(\"ðŸ”¹ Final Classification Report:\\n\", report_final)\n",
    "\n",
    "# ðŸš€ **Step 9: Save the Final Optimized Model**\n",
    "joblib.dump(final_xgb, \"final_optimized_xgboost_model.pkl\")\n",
    "print(\"âœ… Final Model saved as 'final_optimized_xgboost_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60ec219d-fbf1-4259-8d7b-809188b7aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [02:12:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost Accuracy: 0.9095\n",
      "âœ… XGBoost model saved as 'xgboost_model.pkl'\n",
      "ðŸ”¹ Training Random Forest...\n",
      "âœ… Random Forest Accuracy: 0.8864\n",
      "âœ… Random Forest model saved as 'random_forest_model.pkl'\n",
      "ðŸ”¹ Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 83550, number of negative: 276590\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1101\n",
      "[LightGBM] [Info] Number of data points in the train set: 360140, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.231993 -> initscore=-1.197091\n",
      "[LightGBM] [Info] Start training from score -1.197091\n",
      "âœ… LightGBM Accuracy: 0.9039\n",
      "âœ… LightGBM model saved as 'lightgbm_model.pkl'\n",
      "ðŸ”¹ Training Logistic Regression...\n",
      "âœ… Logistic Regression Accuracy: 0.8067\n",
      "âœ… Logistic Regression model saved as 'logistic_regression_model.pkl'\n",
      "\n",
      "ðŸ”¹ XGBoost Model Results:\n",
      "Accuracy: 0.9095\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     69148\n",
      "           1       0.89      0.70      0.78     20888\n",
      "\n",
      "    accuracy                           0.91     90036\n",
      "   macro avg       0.90      0.84      0.86     90036\n",
      "weighted avg       0.91      0.91      0.91     90036\n",
      "\n",
      "\n",
      "ðŸ”¹ Random Forest Model Results:\n",
      "Accuracy: 0.8864\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     69148\n",
      "           1       0.94      0.55      0.69     20888\n",
      "\n",
      "    accuracy                           0.89     90036\n",
      "   macro avg       0.91      0.77      0.81     90036\n",
      "weighted avg       0.89      0.89      0.87     90036\n",
      "\n",
      "\n",
      "ðŸ”¹ LightGBM Model Results:\n",
      "Accuracy: 0.9039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     69148\n",
      "           1       0.89      0.67      0.76     20888\n",
      "\n",
      "    accuracy                           0.90     90036\n",
      "   macro avg       0.90      0.82      0.85     90036\n",
      "weighted avg       0.90      0.90      0.90     90036\n",
      "\n",
      "\n",
      "ðŸ”¹ Logistic Regression Model Results:\n",
      "Accuracy: 0.8067\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89     69148\n",
      "           1       0.73      0.26      0.38     20888\n",
      "\n",
      "    accuracy                           0.81     90036\n",
      "   macro avg       0.77      0.62      0.64     90036\n",
      "weighted avg       0.79      0.81      0.77     90036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ðŸš€ **Step 1: Load the Dataset**\n",
    "df = pd.read_csv(\"urldata.csv\")  # Your dataset with PhishTank data\n",
    "\n",
    "# âœ… Fix: Convert 'benign' and 'malicious' to numerical labels\n",
    "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1})\n",
    "\n",
    "# ðŸš€ **Step 2: Feature Extraction**\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "    \n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)\n",
    "    }\n",
    "\n",
    "df_features = df[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())\n",
    "\n",
    "# Labels\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ðŸš€ **Step 3: Split Data**\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ðŸš€ **Step 4: Define Models**\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=300, max_depth=9, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, gamma=0.1, objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=300, max_depth=9, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500)\n",
    "}\n",
    "\n",
    "# ðŸš€ **Step 5: Train and Evaluate Each Model**\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"ðŸ”¹ Training {name}...\")\n",
    "    model.fit(X_train, y_train)  # âœ… FIXED: Now y_train contains only 0 and 1\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"âœ… {name} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Save Model\n",
    "    joblib.dump(model, f\"{name.lower().replace(' ', '_')}_model.pkl\")\n",
    "    print(f\"âœ… {name} model saved as '{name.lower().replace(' ', '_')}_model.pkl'\")\n",
    "\n",
    "    # Store Results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Classification Report\": classification_report(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# ðŸš€ **Step 6: Print Final Results**\n",
    "for name, result in results.items():\n",
    "    print(f\"\\nðŸ”¹ {name} Model Results:\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\\n\", result[\"Classification Report\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86fa754-c3cc-48a8-ae88-39b21a8f4a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'xgboost' has no attribute 'XGBClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(df_features, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ðŸš€ **Step 4: Define XGBoost Model**\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBClassifier\u001b[49m(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# ðŸš€ **Step 5: Define Hyperparameter Space for Randomized Search**\u001b[39;00m\n\u001b[1;32m     45\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m],  \u001b[38;5;66;03m# Number of trees\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m],  \u001b[38;5;66;03m# Depth of trees\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m],  \u001b[38;5;66;03m# Minimum loss reduction\u001b[39;00m\n\u001b[1;32m     52\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'xgboost' has no attribute 'XGBClassifier'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ðŸš€ **Step 1: Load Dataset**\n",
    "df = pd.read_csv(\"urldata.csv\")  # Your dataset with PhishTank data\n",
    "\n",
    "# âœ… Convert labels to 0 and 1\n",
    "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1})\n",
    "\n",
    "# ðŸš€ **Step 2: Feature Extraction**\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "    \n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)\n",
    "    }\n",
    "\n",
    "df_features = df[\"url\"].apply(lambda x: extract_url_features(x))\n",
    "df_features = pd.DataFrame(df_features.tolist())\n",
    "\n",
    "# Labels\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ðŸš€ **Step 3: Split Data**\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ðŸš€ **Step 4: Define XGBoost Model**\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False)\n",
    "\n",
    "# ðŸš€ **Step 5: Define Hyperparameter Space for Randomized Search**\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],  # Number of trees\n",
    "    \"max_depth\": [3, 6, 9, 12],  # Depth of trees\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9],  # Data sampling\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],  # Feature sampling\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.3, 0.4],  # Minimum loss reduction\n",
    "}\n",
    "\n",
    "# ðŸš€ **Step 6: Perform Randomized Search with K-Fold Cross-Validation**\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Number of random combinations to test\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters from Randomized Search\n",
    "best_params_random = random_search.best_params_\n",
    "print(f\"âœ… Best Parameters from Randomized Search: {best_params_random}\")\n",
    "\n",
    "# ðŸš€ **Step 7: Fine-Tune with Grid Search**\n",
    "param_grid = {\n",
    "    \"n_estimators\": [best_params_random[\"n_estimators\"] - 50, best_params_random[\"n_estimators\"], best_params_random[\"n_estimators\"] + 50],\n",
    "    \"max_depth\": [best_params_random[\"max_depth\"] - 1, best_params_random[\"max_depth\"], best_params_random[\"max_depth\"] + 1],\n",
    "    \"learning_rate\": [best_params_random[\"learning_rate\"] * 0.8, best_params_random[\"learning_rate\"], best_params_random[\"learning_rate\"] * 1.2],\n",
    "    \"subsample\": [best_params_random[\"subsample\"]],\n",
    "    \"colsample_bytree\": [best_params_random[\"colsample_bytree\"]],\n",
    "    \"gamma\": [best_params_random[\"gamma\"]]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=kfold,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 8: Train Final Model with Best Parameters**\n",
    "best_params_grid = grid_search.best_params_\n",
    "print(f\"âœ… Best Parameters from Grid Search: {best_params_grid}\")\n",
    "\n",
    "final_xgb = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    **best_params_grid\n",
    ")\n",
    "\n",
    "final_xgb.fit(X_train, y_train)\n",
    "\n",
    "# ðŸš€ **Step 9: Make Predictions**\n",
    "y_pred_final = final_xgb.predict(X_test)\n",
    "\n",
    "# ðŸš€ **Step 10: Evaluate Model Performance**\n",
    "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "report_final = classification_report(y_test, y_pred_final)\n",
    "\n",
    "print(f\"ðŸ”¹ Final Fine-Tuned Accuracy: {accuracy_final:.4f}\")\n",
    "print(\"ðŸ”¹ Final Classification Report:\\n\", report_final)\n",
    "\n",
    "# ðŸš€ **Step 11: Save the Final Optimized Model**\n",
    "##joblib.dump(final_xgb, \"final_optimized_xgboost_model.pkl\")\n",
    "##print(\"âœ… Final Model saved as 'final_optimized_xgboost_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a5bf53-8113-49f5-9625-8601054373ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost.sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ðŸš€ **Step 1: Load Your Trained XGBoost Model**\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_optimized_xgboost_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Make sure this file exists\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost.sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import \n",
    "# ðŸš€ **Step 1: Load Your Trained XGBoost Model**\n",
    "model_path = \"final_optimized_xgboost_model.pkl\"  # Make sure this file exists\n",
    "optimized_xgb = joblib.load(model_path)\n",
    "\n",
    "# ðŸš€ **Step 2: Define Feature Extraction Function**\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "    \n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)\n",
    "    }\n",
    "\n",
    "# ðŸš€ **Step 3: Define URLs to Test**\n",
    "test_urls = [\n",
    "    # âœ… Safe (Benign) URLs\n",
    "    \"https://google.com\",\n",
    "    \"https://www.facebook.com\",\n",
    "    \"https://full-stack-frontend-4b7r.onrender.com/\",\n",
    "    \"https://student.srmap.edu.in\",\n",
    "    \"https://securexnow.com/\",\n",
    "    \n",
    "    # âŒ Malicious (Phishing/Scam) URLs\n",
    "    \"https://wordsonawall.net/ub/lmicu/login.php\",\n",
    "    \"http://secure-login.bankofamerica-verify.com\",\n",
    "    \"http://free-money-giveaway.com\",\n",
    "    \"http://update-your-banking-details.com\",\n",
    "    \"http://win-a-free-iphone.com\",\n",
    "]\n",
    "\n",
    "# ðŸš€ **Step 4: Convert URLs into Features**\n",
    "test_features = pd.DataFrame([extract_url_features(url) for url in test_urls])\n",
    "\n",
    "# ðŸš€ **Step 5: Make Predictions**\n",
    "test_predictions = optimized_xgb.predict(test_features)\n",
    "\n",
    "# ðŸš€ **Step 6: Display Results**\n",
    "test_results = pd.DataFrame({\"URL\": test_urls, \"Prediction\": test_predictions})\n",
    "test_results[\"Prediction\"] = test_results[\"Prediction\"].map({0: \"Benign (Safe)\", 1: \"Malicious\"})\n",
    "\n",
    "# Print Results\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "785e8fcb-876e-4591-951f-100993aeedc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting htmldom\n",
      "  Downloading htmldom-2.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: htmldom\n",
      "  Building wheel for htmldom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmldom: filename=htmldom-2.0-py3-none-any.whl size=11116 sha256=466d71adc85f17c081765a0509063658820e78d688b41be2480445a72e76b1c6\n",
      "  Stored in directory: /Users/tejashtarun/Library/Caches/pip/wheels/68/87/53/032cf8ecf90d9446b2f48b82ab76dce9b7021034014f21c58e\n",
      "Successfully built htmldom\n",
      "Installing collected packages: htmldom\n",
      "Successfully installed htmldom-2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install htmldom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f544392-2342-4023-a9c6-529f277f9a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Data Type: <class 'dict'>\n",
      "ðŸ”¹ Keys in the dataset: dict_keys(['http://loveslife.biz/', 'http://www.team-meble.pl/', 'http://base.etagy.net/login.php', 'https://www.slideshare.net/gregrobertson/tp-sforblog', 'http://www.yourdictionary.com/iconoclast', 'http://www.campisicorradomichele.com/public/_vti_cnf/mo.php', 'https://www.vulkanland-bio-safran.at/wp-admin/install.php', 'https://kinomaxxcinema.wordpress.com/', 'https://umcutrecht.nl/nl/', 'https://www.gyu-kaku.com/', 'http://www.everythingwakeboard.com/Cap/Pack/', 'https://rebrand.ly/9m831w', 'http://hostpoint-admin-panel52358.web65.s177.goserver.host/hostpoint/index.html', 'https://www.kmc.si/', 'https://drive.google.com/file/d/1kNolZ4xw7mgnCSjYsbomy_y4zxlk6zlD/view?usp=sharing', 'https://rebrand.ly/Security_Check_Center', 'https://www.hdofasheville.com/', 'https://www.limerius.com/', 'http://www.whatsapps-invites.zzux.com/', 'http://lbcpzonasegurabeta.rf.gd/', 'http://www.fjyyqp.com/statics/plugin/kindeditor/attached/file/20170124/20170124101027_54480.html', 'http://gurpreeth.blogspot.com/', 'http://ogoapes.weebly.com', 'http://hackaday.com/2017/03/22/well-engineered-radio-clock-aces-form-and-function/', 'https://personalbravery.com/authflow/verification/', 'https://stackoverflow.com/questions/9444055/using-dns-to-redirect-to-another-url-with-a-path', 'http://brighant.com/1122/?sec=Danielle', 'http://resbet.blogspot.com', 'http://adexten.com/?type=social&amp;pub_id=3283&amp;sub_id=1498560000mb13539492009&amp;srcid=2108', 'http://alatest.nl', 'https://www.muckrock.com/agency/united-states-of-america-10/uspacom-108/', 'https://www.history.org.uk/', 'https://envicom.nl/wp-includes/images/noos/ned/NedbankMoney.htm', 'http://gizmodo.com/everything-you-can-and-cant-do-with-the-new-nokia-331-1792785860', 'http://rudiguvenlik.com/1122/?sec=Andreas', 'http://www.bionity.com/en/encyclopedia/Pathogen.html', 'http://www1.salary.com/Software-Engineer-Salary.html', 'http://smallbusiness.chron.com/disadvantages-proprietary-software-65430.html', 'http://www.pocketlegends.com/', 'https://www.tumblr.com/safe-mode?url=http%3A%2F%2Fel-rincon-del-gordo.tumblr.com%2F', 'https://www.booktable.net/', 'http://findicons.com/search/parking', 'http://www.feriados.com.br/', 'https://www.login-bank.org/bremer-bank', 'https://sites.google.com/site/suportunblockscuritycentre/', 'http://www.bdmifund.com/', 'http://bpbd.ngawikab.go.id/googleDoc/GoogleDoc/files/', 'http://www.esquire.com/food-drink/drinks/a30663/session-beer-is-dumb/', 'http://email.veromailer.com/c/eJx1kV1v2jAUhn9NuKlAxs6XL3IRCmEdYp1aJlZukLFNPurYnnMKDb9-CVvbTNUky7LPefz6PedwVltW5toLZk7y0pZSw16YmpVdaJ44aCzjzywvdT7hph7xD152kNo3L4dKcujh7_c3HibbcUAIDvyRSBiJER0-OTFXMijNVfvWaHBGjcoEI4wQxv408ANCJ9NJlt4uMroI51lMshnyPR-dpOtdKemuPoqESj9EPo0lp_yADofQF0caxCKI5ZFFERu5BJhjk9yxgtWdwqdaVFIA2MYjqYezbgnDm0luTK5kn-8iL9wjmXy1xoFH5sKctTJMeDgsRXefBhtox6pa2Of00aV6h36dH0J2WUIg9Ubchx3Y295f6aGZrj2f7LzB3OhTh-9Dtd4ogXS8unA2u8wvPwvYfeX2CY7r6i63X15zMq3bxXkXuadVtKpPrq0KaHNYIi2rmMJiO1v_ENjhNK2Ac_x4t16nZ7VqtlHk90UHZH7dhiP6_zwH0Nuxr6wDI0JRFA8B60yvsteslj3xUPKCOXGzlFqYdkhCa6_EN3lulASQ7p-srK1iIN-FRpD0XRr_-XIc0dCP6N_gbxt565U', 'http://www.payscale.com/research/US/Job=Digital_Signal_Processing_(DSP)_Engineer/Salary', 'https://www.youtube.com/user/linkinparktv', 'http://stolizaparketa.ru/wp-content/themes/twentyfifteen/css/read/chinavali/index.php?email=xxx@yyy.com/', 'https://www.doiser.com/', 'https://yea.to/VERIFY-ATM', 'http://raulbeneitez.cat/', 'http://rockysite.net/', 'http://retranslyator.blogspot.ru/p/iptv-playlist.html', 'https://www.servicemax.com/cp/software-as-a-service-providers', 'https://en.wikipedia.org/wiki/United_States_Pacific_Command', 'https://docs.google.com/forms/d/e/1FAIpQLSfttS12wZ9DLNWcmDvgE38oWrINS8y7cxnYT_fTNdAcEf03GA/viewform?usp=send_form', 'http://ttdancestudio.com/ap_application/application/controllers/tesla', 'https://sra.mn/', 'https://www.sejapremium.com.br/', 'https://www.youtube.com/watch?v=TNKWgcFPHqw', 'http://art-market.com.ua', 'http://global.ncsoft.com/global/', 'http://hag-info.ch', 'http://www.homeandlearn.org/open_a_text_file_in_vba.html', 'https://twitter.com/nbc4i', 'http://www.thesaurus.com/browse/impact', 'http://www.thatsmint.work/5wq/irs/', 'http://1sultanbet.blogspot.com', 'http://www.jp519.com/', 'http://starmak.com.tr/950CAAEA0281AA2BEBED8F9ECCA4BD30/?sec=redacteddetcader', 'http://www.fuertecondor.com/img/', 'https://www.encyclopediaofmath.org/index.php/Connected_space', 'http://www.accaparlante.it/', 'http://g102d3e13e313e1.com/ap/', 'http://www.movie-censorship.com/report.php?ID=660092', 'http://eshaan.co.uk/zo/1/login.htm', 'https://www.w3schools.com/Asp/asp_ref_filesystem.asp', 'https://access.redhat.com/solutions/70464', 'http://www.eurogamer.net/articles/2017-04-13-nintendo-switch-games-list-2017-release-dates', 'http://betcupgirisadresimiz1.blogspot.com', 'https://www.youtube.com/watch?v=qkJ53ftas_M', 'https://www.kotirinki.fi/', 'https://www.youtube.com/user/VoltaireMusicPage', 'http://www.gatepaper.in', 'http://www.prostudioconnection.com/Default.asp', 'http://www.m.crosswordheaven.net/clues/railroad-switches', 'https://www.etsy.com/market/number_balloons', 'http://www.artemusgroupusa.com/wp-content/uploads/omoowoo/image.htm', 'https://www.pioneerbanking.com/', 'http://www.investopedia.com/terms/s/software-as-a-service-saas.asp', 'http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.428.8805&rep=rep1&type=pdf', 'http://phoenixlocksmith-az.com/prole/?p', 'https://www.crownhoteltm.com/', 'https://docs.google.com/forms/d/e/1FAIpQLSe0H5Q3v0zw136co7xLVdnPCHJewwbrttlNlXtzwnEMctdrIw/viewform?usp=send_form', 'http://www.majorgeeks.com/mg/sortname/file_managers_41d9.html', 'https://fgoten-mole.web.app/'])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the pickle file\n",
    "dataset_path = \"dataset_A_05_2020_p10.pickle\"  # Replace with your actual file name\n",
    "data = joblib.load(dataset_path)\n",
    "\n",
    "# Check the type of the loaded object\n",
    "print(f\"âœ… Loaded Data Type: {type(data)}\")\n",
    "\n",
    "# If it's a dictionary, print the keys\n",
    "if isinstance(data, dict):\n",
    "    print(f\"ðŸ”¹ Keys in the dataset: {data.keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeffae83-b12b-4d9f-bf3b-3f1b5029cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Updated Phishing Detection Results:\n",
      "                                  Original URL                                 Normalized URL                                Domain    Prediction\n",
      "                           https://chatgpt.com                            https://chatgpt.com                           chatgpt.com Benign (Safe)\n",
      "                        https://www.google.com                         https://www.google.com                            google.com Benign (Safe)\n",
      "                      https://www.facebook.com                       https://www.facebook.com                          facebook.com Benign (Safe)\n",
      "https://full-stack-frontend-4b7r.onrender.com/ https://full-stack-frontend-4b7r.onrender.com/ full-stack-frontend-4b7r.onrender.com Benign (Safe)\n",
      "                  https://student.srmap.edu.in                   https://student.srmap.edu.in                  student.srmap.edu.in Benign (Safe)\n",
      "                       https://securexnow.com/                        https://securexnow.com/                        securexnow.com     Malicious\n",
      "   https://wordsonawall.net/ub/lmicu/login.php    https://wordsonawall.net/ub/lmicu/login.php                      wordsonawall.net     Malicious\n",
      "  http://secure-login.bankofamerica-verify.com   http://secure-login.bankofamerica-verify.com secure-login.bankofamerica-verify.com     Malicious\n",
      "                http://free-money-giveaway.com                 http://free-money-giveaway.com               free-money-giveaway.com     Malicious\n",
      "        http://update-your-banking-details.com         http://update-your-banking-details.com       update-your-banking-details.com     Malicious\n",
      "                  http://win-a-free-iphone.com                   http://win-a-free-iphone.com                 win-a-free-iphone.com     Malicious\n",
      "\n",
      "âœ… Results saved as 'phishing_detection_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# ðŸš€ Load the trained XGBoost model\n",
    "model_path = \"final_optimized_xgboost_model.pkl\"  # Ensure this file exists\n",
    "optimized_xgb = joblib.load(model_path)\n",
    "\n",
    "# âœ… Trusted domains whitelist (Override model decision)\n",
    "TRUSTED_DOMAINS = {\n",
    "    \"chatgpt.com\",\n",
    "    \"instagram.com\",\n",
    "    \"render.com\",\n",
    "    \"x.com\",\n",
    "    \"amazon.com\",\n",
    "    \"www.amazon.com\",\n",
    "    \"linkedin.com\",\n",
    "    \"www.linkedin.com\",\n",
    "    \"github.com\",\n",
    "    \"www.github.com\"\n",
    "}\n",
    "\n",
    "# ðŸš€ Function to Normalize and Extract Domain\n",
    "def normalize_url(url):\n",
    "    \"\"\"Normalize URL by removing 'www.' for consistency.\"\"\"\n",
    "    if not url.startswith(\"http\"):\n",
    "        url = \"https://\" + url  # Ensure URL has a scheme\n",
    "    \n",
    "    parsed = urlparse(url)\n",
    "    domain = parsed.netloc.lower()\n",
    "\n",
    "    # Convert www.google.com to google.com\n",
    "    if domain.startswith(\"www.\"):\n",
    "        domain = domain[4:]\n",
    "\n",
    "    return url, domain\n",
    "\n",
    "# ðŸš€ Feature Extraction\n",
    "def extract_url_features(url):\n",
    "    suspicious_words = [\"secure\", \"login\", \"verify\", \"update\", \"free\", \"gift\", \"money\", \"account\"]\n",
    "\n",
    "    return {\n",
    "        \"url_length\": len(url),\n",
    "        \"num_hyphens\": url.count(\"-\"),\n",
    "        \"num_underscores\": url.count(\"_\"),\n",
    "        \"num_slashes\": url.count(\"/\"),\n",
    "        \"num_digits\": sum(c.isdigit() for c in url),\n",
    "        \"num_subdomains\": url.count(\".\") - 1,\n",
    "        \"contains_ip\": 1 if re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", url) else 0,\n",
    "        \"num_special_chars\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\"),\n",
    "        \"digit_ratio\": sum(c.isdigit() for c in url) / len(url),\n",
    "        \"special_char_ratio\": sum(url.count(c) for c in \"!@#$%^&*()+=[]{}|\\\\:;\\\"'<>,?\") / len(url),\n",
    "        \"suspicious_word_count\": sum(1 for word in suspicious_words if word in url)\n",
    "    }\n",
    "\n",
    "# ðŸš€ Test URLs\n",
    "test_urls = [\n",
    "    \"https://chatgpt.com\",\n",
    "    \"https://www.google.com\",\n",
    "    \"https://www.facebook.com\",\n",
    "    \"https://full-stack-frontend-4b7r.onrender.com/\",\n",
    "    \"https://student.srmap.edu.in\",\n",
    "    \"https://securexnow.com/\",\n",
    "    \n",
    "    # âŒ Malicious URLs\n",
    "    \"https://wordsonawall.net/ub/lmicu/login.php\",\n",
    "    \"http://secure-login.bankofamerica-verify.com\",\n",
    "    \"http://free-money-giveaway.com\",\n",
    "    \"http://update-your-banking-details.com\",\n",
    "    \"http://win-a-free-iphone.com\",\n",
    "]\n",
    "\n",
    "# ðŸš€ Process URLs\n",
    "normalized_urls = []\n",
    "domains = []\n",
    "for url in test_urls:\n",
    "    norm_url, domain = normalize_url(url)\n",
    "    normalized_urls.append(norm_url)\n",
    "    domains.append(domain)\n",
    "\n",
    "# ðŸš€ Extract Features\n",
    "test_features = pd.DataFrame([extract_url_features(url) for url in normalized_urls])\n",
    "\n",
    "# ðŸš€ Make Predictions\n",
    "test_predictions = optimized_xgb.predict(test_features)\n",
    "\n",
    "# ðŸš€ Override Model for Trusted Domains\n",
    "final_predictions = []\n",
    "for i, domain in enumerate(domains):\n",
    "    if domain in TRUSTED_DOMAINS:\n",
    "        final_predictions.append(0)  # Force to \"Benign\"\n",
    "    else:\n",
    "        final_predictions.append(test_predictions[i])\n",
    "\n",
    "# ðŸš€ Display Results\n",
    "test_results = pd.DataFrame({\n",
    "    \"Original URL\": test_urls,\n",
    "    \"Normalized URL\": normalized_urls,\n",
    "    \"Domain\": domains,\n",
    "    \"Prediction\": final_predictions\n",
    "})\n",
    "\n",
    "# âœ… Convert Predictions to Readable Labels\n",
    "test_results[\"Prediction\"] = test_results[\"Prediction\"].map({0: \"Benign (Safe)\", 1: \"Malicious\"})\n",
    "\n",
    "# âœ… Print results\n",
    "print(\"\\nðŸ”¹ Updated Phishing Detection Results:\")\n",
    "print(test_results.to_string(index=False))\n",
    "\n",
    "# âœ… Save results\n",
    "test_results.to_csv(\"phishing_detection_results.csv\", index=False)\n",
    "print(\"\\nâœ… Results saved as 'phishing_detection_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5f9bb-7c3a-4880-8d0a-41b257f9c629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
